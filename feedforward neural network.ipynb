{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generate data\n",
    "np.random.seed(1)\n",
    "X = np.random.rand(12288, 200)\n",
    "Y = np.random.rand(1, 200)\n",
    "\n",
    "# setup configuration of the network\n",
    "n0, m = X.shape\n",
    "n1 = 20\n",
    "n2 = 7\n",
    "n3 = 5\n",
    "n4 = 1\n",
    "layers_dims = [n0, n1, n2, n3, n4] ## [12288, 20, 7, 5, 1]\n",
    "L = len(layers_dims) - 1 # the number of the layers, excluding the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### activation functions\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    z为prev_activation, size为 nl * m\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    '''\n",
    "    z为prev_activation, size为 nl * m\n",
    "    '''\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### neural network model\n",
    "def neural_network(X, Y, learning_rate=0.01, num_iterations=2000, lambd=0):\n",
    "    m = X.shape[1]\n",
    "    ### initialize forward propagation\n",
    "    param_w = [i for i in range(L+1)]\n",
    "    param_b = [i for i in range(L+1)]\n",
    "    np.random.seed(10)\n",
    "    for l in range(1, L+1):\n",
    "        if l < L:\n",
    "            # use He initialization\n",
    "            param_w[l] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(2 / layers_dims[l - 1])\n",
    "        if l == L:\n",
    "            param_w[l] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * 0.01\n",
    "        param_b[l] = np.zeros((layers_dims[l], 1))\n",
    "\n",
    "    activations = [X, ] + [i for i in range(L)]\n",
    "    prev_activations = [i for i in range(L+1)]\n",
    "\n",
    "    dA = [i for i in range(L+1)]\n",
    "    dz = [i for i in range(L+1)]\n",
    "    dw = [i for i in range(L+1)]\n",
    "    db = [i for i in range(L+1)]\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        ### forward propagation\n",
    "        for l in range(1, L+1):\n",
    "            prev_activations[l] = np.dot(param_w[l], activations[l-1]) + param_b[l]\n",
    "            if l < L:\n",
    "                activations[l] = relu(prev_activations[l])\n",
    "            else:\n",
    "                activations[l] = sigmoid(prev_activations[l])\n",
    "\n",
    "        cross_entropy_cost = -1/m * (np.dot(np.log(activations[L]), Y.T) \\\n",
    "                                     + np.dot(np.log(1-activations[L]), 1-Y.T))\n",
    "        regularization_cost = 0\n",
    "        for l in range(1, L+1):\n",
    "            regularization_cost += np.sum(np.square(param_w[l])) * lambd/(2*m)\n",
    "        cost = cross_entropy_cost + regularization_cost\n",
    "\n",
    "        ### initialize backward propagation\n",
    "        dA[L] =  np.divide(1-Y, 1-activations[L]) - np.divide(Y, activations[L])\n",
    "        assert dA[L].shape == (1, m)\n",
    "\n",
    "        ### backward propagation\n",
    "        for l in reversed(range(1, L+1)):\n",
    "            if l == L:\n",
    "                dz[l] = dA[l] * activations[l] * (1-activations[l])\n",
    "            else:\n",
    "                dz[l] = dA[l].copy()\n",
    "                dz[l][prev_activations[l] <= 0] = 0\n",
    "\n",
    "            dw[l] = 1/m * np.dot(dz[l], activations[l-1].T) + param_w[l] * lambd/m\n",
    "            db[l] = 1/m * np.sum(dz[l], axis=1, keepdims=True)\n",
    "            dA[l-1] = np.dot(param_w[l].T, dz[l])\n",
    "\n",
    "            assert dz[l].shape == prev_activations[l].shape\n",
    "            assert dw[l].shape == param_w[l].shape\n",
    "            assert db[l].shape == param_b[l].shape\n",
    "            assert dA[l-1].shape == activations[l-1].shape\n",
    "\n",
    "            param_w[l] = param_w[l] - learning_rate * dw[l]\n",
    "            param_b[l] = param_b[l] - learning_rate * db[l]\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"cost after iteration {}: {}\".format(i, cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict\n",
    "def predict(X_new, parameters, threshold=0.5):\n",
    "    param_w = parameters[\"param_w\"]\n",
    "    param_b = parameters[\"param_b\"]\n",
    "\n",
    "    activations = [X_new, ] + [i for i in range(L)]\n",
    "    prev_activations = [i for i in range(L + 1)]\n",
    "    m = X_new.shape[1]\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        prev_activations[l] = np.dot(param_w[l], activations[l - 1]) + param_b[l]\n",
    "        if l < L:\n",
    "            activations[l] = relu(prev_activations[l])\n",
    "        else:\n",
    "            activations[l] = sigmoid(prev_activations[l])\n",
    "    prediction = (activations[L] > threshold).astype(\"int\")\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
